{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SD6fC1NI23BC"
   },
   "source": [
    "**VEHICLE IDENTIFICATION MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uJyQZiaIEOy"
   },
   "source": [
    "**Get the runtime details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ug9w23rqyygI"
   },
   "outputs": [],
   "source": [
    "%cat/etc/lsb-release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pyo1cuJWv8Uj"
   },
   "source": [
    "**Update the repo list**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URUkar2FzHFK"
   },
   "outputs": [],
   "source": [
    "!apt-get update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVeDSF02wC9l"
   },
   "source": [
    "**show the current working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0Lhbj2JzLyD"
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxgh2JPTwLh1"
   },
   "source": [
    "**Unzip the darknet zip file to the /content folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eW_wcAGIzRKM"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/My Drive/custom_vehicle_model/darknet.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rOXcDGUwiXl"
   },
   "source": [
    "**Go inside the darknet folder of our runtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aH85m09_zYMa"
   },
   "outputs": [],
   "source": [
    "%cd /content/darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywPdkC9VwxN1"
   },
   "source": [
    "**Install dos2unix to convert dos files to unix encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-oxITc-zcSq"
   },
   "outputs": [],
   "source": [
    "!sudo apt install dos2unix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxCf8iqOw2vw"
   },
   "source": [
    "**Convert all files in darknet folder to unix encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QpKNIShzhMp"
   },
   "outputs": [],
   "source": [
    "!find . -type f -print0 | xargs -0 dos2unix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSwu34Imw-Nl"
   },
   "source": [
    "**Give executable permission for files in /content/darknet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKGWx6KPzmUN"
   },
   "outputs": [],
   "source": [
    "!chmod +x /content/darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MmMrHcjxLa-"
   },
   "source": [
    "**make sure of the current working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZcjrpClzsQg"
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqQh5fzpxSVO"
   },
   "source": [
    "**Compile the darknet framework**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UX60LNqzw27"
   },
   "outputs": [],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8Dt89AcyJqU"
   },
   "source": [
    "**Test the darknet framework with sample object detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDZXQ-yrz05P"
   },
   "outputs": [],
   "source": [
    "!./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights data/person.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb0ClT530LYv"
   },
   "source": [
    "**Remove the backup folder of darknet in runtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0kq5kDSz6zQ"
   },
   "outputs": [],
   "source": [
    "!rm /content/darknet/backup -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gA4rXauC0j91"
   },
   "source": [
    "**Create a symbolic link from runtime darknet folder to google drive backup folder with the name 'backup'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rUSn4Oxz_qC"
   },
   "outputs": [],
   "source": [
    "!ln -s /content/drive/'My Drive'/obj_weights/backup /content/darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrrjL2oG1K3c"
   },
   "source": [
    "**check the directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFZwhp_v0FN-"
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-07zjiWFBugo"
   },
   "source": [
    "**Proceed with fresh training using the vehicle dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5YNJAEVKqgI"
   },
   "outputs": [],
   "source": [
    "!./darknet detector train obj_data/obj.data obj_yolov4.cfg yolov4.conv.137 -map -dont_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn3ICgMAmVDK"
   },
   "source": [
    "**Resume training from the last best weight file if required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNhaAaDb0msD"
   },
   "outputs": [],
   "source": [
    "!./darknet detector train obj_data/obj.data obj_yolov4.cfg /content/drive/'My Drive'/obj_weights/backup/obj_yolov4_best.weights -map -dont_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Px_2cj9HBY27"
   },
   "source": [
    "**Resume training from the last best weight file if required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ypawx6USBbQ4"
   },
   "outputs": [],
   "source": [
    "!./darknet detector train obj_data/obj.data obj_yolov4.cfg /content/drive/'My Drive'/obj_weights/backup/obj_yolov4_best.weights -map -dont_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSsH0o-IwZ2b"
   },
   "source": [
    "**Resume training from the last best weight file if required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9HTjnydrw6O"
   },
   "outputs": [],
   "source": [
    "!./darknet detector train obj_data/obj.data obj_yolov4.cfg /content/drive/'My Drive'/obj_weights/backup/obj_yolov4_best.weights -map -dont_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOEnqCG0roqZ"
   },
   "source": [
    "**import the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZ3HYg1IrzJR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1OAd1TCr2t8"
   },
   "source": [
    "**get the video stream**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UI7KCDybr9kH"
   },
   "outputs": [],
   "source": [
    "file_video_stream = cv2.VideoCapture('obj_data/obj_videos/64.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AB8pWtFKtcWn"
   },
   "source": [
    "**create a while loop, loop till the last frame of the video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N00VlKBwtKSY"
   },
   "outputs": [],
   "source": [
    "while (file_video_stream.isOpened()):\n",
    "    # for every iteration obtain the current frame from video stream by using the read function\n",
    "    ret, current_frame = file_video_stream.read()\n",
    "    # ret is a bool value which indicates whether the read function was able to read the video stream correctly or not \n",
    "    # pass this current_frame to the object detector instead of testing image\n",
    "    img_to_detect = current_frame\n",
    "    \n",
    "    img_height = img_to_detect.shape[0]\n",
    "    img_width = img_to_detect.shape[1]\n",
    "    \n",
    "    # convert the image to blob(binary large object) to pass into model\n",
    "    img_blob = cv2.dnn.blobFromImage(img_to_detect, 0.003922, (416,416),\n",
    "                                     swapRB = True, crop = False)\n",
    "    # recommended by yolo authors, scale factor is 0.003922 = 1/255 (255 is the maximum color value of a pixel in the image), width,height of  \n",
    "    # blob is (320,320). Accepted sizes are (320 x 320), (416 x 416), (609 x 609).More size means more accuracy but less speed.\n",
    "    # swapRB is set true bcoz originally the colour format in the image is RGB(red,green,blue) but opencv library \n",
    "    # converts it to BGR(blue,green,red), so to use it as binary large image we convert it back to RGB.\n",
    "    \n",
    "    # set of 4 custom class labels\n",
    "    class_labels = [\"car\",\"truck\",\"motorcycle\",\"bus\"]\n",
    "    \n",
    "    # declare list of colors as an array\n",
    "    # green,blue,red,cyan,yellow,purple\n",
    "    # Split based on ',' and for every split, change type to int\n",
    "    # convert that to a numpy array to apply color mask to the image numpy array\n",
    "    \n",
    "    class_colors = [\"0,255,0\", \"0,0,255\", \"255,0,0\", \"255,255,0\"]\n",
    "    # print(class_colors)\n",
    "    class_colors = [np.array(every_color.split(\",\")).astype(int) \n",
    "                    for every_color in class_colors]\n",
    "    # print(class_colors)\n",
    "    class_colors = np.array(class_colors)\n",
    "    # print(class_colors)\n",
    "    class_colors = np.tile(class_colors, (1,1))\n",
    "    # print(class_colors)\n",
    "    \n",
    "    # loading pretrained model\n",
    "    yolo_model = cv2.dnn.readNetFromDarknet('obj_yolov4.cfg','obj_yolov4_best.weights')\n",
    "    \n",
    "    # Get all layers from the yolo network\n",
    "    # Loop & find the last layer(output layer) of the yolo network\n",
    "    yolo_layers = yolo_model.getLayerNames()\n",
    "    # print(yolo_layers)\n",
    "    yolo_output_layer = [yolo_layers[yolo_layer[0] - 1] for yolo_layer in yolo_model.getUnconnectedOutLayers()]\n",
    "    # print(yolo_output_layer)\n",
    "    \n",
    "    # input preprocessed blob into the model & pass through the model\n",
    "    yolo_model.setInput(img_blob)\n",
    "    \n",
    "    # Obtain the detection predictions by the model using forward() method or\n",
    "    # obtain the detection layers by forwarding through till the output layer\n",
    "    obj_detection_layers = yolo_model.forward(yolo_output_layer)\n",
    "    # print(obj_detection_layers)\n",
    "    \n",
    "    ######## NMS Change 1 ########\n",
    "    # initialization for non-maximum supression(NMS)\n",
    "    # declare list for [class id], [box_centre, width & height], [confidences]\n",
    "    class_ids_list = []\n",
    "    boxes_list = []\n",
    "    confidences_list = []\n",
    "    ######## NMS Change 1 END ########\n",
    "    \n",
    "    # loop over each of the layer outputs\n",
    "    for object_detection_layer in obj_detection_layers:\n",
    "        # loop over the detections\n",
    "        for object_detection in object_detection_layer:\n",
    "            # object_detection[1 to 4] => will have two centre points, box width   \n",
    "            # & box height\n",
    "            # obj_detection[5] => will have scores for all objects within  \n",
    "            # bounding box\n",
    "        \n",
    "            all_scores = object_detection[5:]\n",
    "            predicted_class_id = np.argmax(all_scores)\n",
    "            prediction_confidence = all_scores[predicted_class_id]\n",
    "            \n",
    "            # take only predictions with confidence more than 20%\n",
    "            if prediction_confidence > 0.20:\n",
    "                # get the predicted label\n",
    "                predicted_class_label = class_labels[predicted_class_id]\n",
    "                # obtain the bounding box co-oridnates for actual image from \n",
    "                # resized image size\n",
    "                bounding_box = object_detection[0:4] * np.array([img_width, img_height, img_width, img_height])\n",
    "                (box_centre_x_pt, box_centre_y_pt, box_width, box_height) = bounding_box.astype(int)\n",
    "                start_x_pt = int(box_centre_x_pt - (box_width/2))\n",
    "                start_y_pt = int(box_centre_y_pt - (box_height/2))\n",
    "                \n",
    "                ############## NMS Change 2 ###############\n",
    "                # save class id, start x, y, width & height, confidences in a list \n",
    "                # for nms processing\n",
    "                # make sure to pass confidence as float and width and height as \n",
    "                # integers\n",
    "                class_ids_list.append(predicted_class_id)\n",
    "                confidences_list.append(float(prediction_confidence))\n",
    "                boxes_list.append([start_x_pt, start_y_pt, int(box_width), int(box_height)])\n",
    "                ############## NMS Change 2 END ###########\n",
    "                \n",
    "    ############## NMS Change 3 ###############\n",
    "    # Applying the NMS will return only the selected max value ids while \n",
    "    # suppressing the non maximum (weak) overlapping bounding boxes      \n",
    "    # Non-Maxima Suppression confidence set as 0.5 & max_suppression threshold \n",
    "    # for NMS as 0.4 (adjust and try for better perfomance)\n",
    "    max_value_ids = cv2.dnn.NMSBoxes(boxes_list, confidences_list, 0.5,0.4)\n",
    "    # max_value_ids will be a list of class_ids sorted descendingly in the order \n",
    "    # of their confidence_values\n",
    "    \n",
    "    # loop through the final set of detections remaining after NMS and draw \n",
    "    # bounding box and write text\n",
    "    my_dict = {} # to keep count of numbers of same class object eg.cars \n",
    "    for max_valueid in max_value_ids:\n",
    "        max_class_id = max_valueid[0]\n",
    "        box = boxes_list[max_class_id]\n",
    "        start_x_pt = box[0]\n",
    "        start_y_pt = box[1]\n",
    "        box_width = box[2]\n",
    "        box_height = box[3]\n",
    "        \n",
    "        #get the predicted class id and label\n",
    "        predicted_class_id = class_ids_list[max_class_id]\n",
    "        predicted_class_label = class_labels[predicted_class_id]\n",
    "        prediction_confidence = confidences_list[max_class_id]\n",
    "    ############## NMS Change 3 END ###########           \n",
    "                \n",
    "        end_x_pt = start_x_pt + box_width\n",
    "        end_y_pt = start_y_pt + box_height\n",
    "        \n",
    "        # get a random mask color from the numpy array of colors\n",
    "        box_color = class_colors[predicted_class_id]\n",
    "        # print(box_color)\n",
    "        \n",
    "        # convert the color numpy array as a list and apply to text & box\n",
    "        box_color = [int(c) for c in box_color]\n",
    "        #print(box_color)\n",
    "        \n",
    "        count = 1 \n",
    "        #print(my_dict.keys())\n",
    "        if predicted_class_label in my_dict.keys():\n",
    "            count = my_dict[predicted_class_label]\n",
    "        \n",
    "        tmp = predicted_class_label\n",
    "        \n",
    "        # print the prediction in console\n",
    "        s = f\"{predicted_class_label} {count} : {(prediction_confidence*100):.2f}\"\n",
    "        predicted_class_label = s\n",
    "        print(f\"predicted object {predicted_class_label}\")\n",
    "        \n",
    "        count+= 1\n",
    "        my_dict[tmp] = count\n",
    "        \n",
    "        # draw rectangle and text in the image\n",
    "        cv2.rectangle(img_to_detect, (start_x_pt, start_y_pt), (end_x_pt, end_y_pt), box_color, 1)\n",
    "        cv2.putText(img_to_detect, predicted_class_label, (start_x_pt, start_y_pt-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 1)\n",
    "    \n",
    "    cv2.imshow(\"Detection Output\", img_to_detect)\n",
    "\n",
    "    # terminate while loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# if keypress detected, release the stream & camera\n",
    "# releasing the stream & camera\n",
    "# then destroy/close all opencv windows\n",
    "file_video_stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
